{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KomisD/Drug-Classification/blob/main/Project2_NNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWd1UlMnhT2s"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install category_encoders"
      ],
      "metadata": {
        "id": "_AsTHmEDkRf6"
      },
      "execution_count": 733,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvGPUQaHhXfL"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "import pandas as pd\n",
        "import category_encoders as ce"
      ],
      "execution_count": 734,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MRC0e0KhQ0S"
      },
      "source": [
        "# Simple Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1VMqkGvhc3-"
      },
      "source": [
        "## Importing the dataset and encoding categorical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M52QDmyzhh9s"
      },
      "source": [
        "dataset = pd.read_csv('drug200.csv')\n",
        "\n",
        "# Applying the binary encoder for SEX\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Sex'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "# Applying the OneHot encoder for blood pressure\n",
        "OneHot = ce.OneHotEncoder(cols=['BP'])\n",
        "dataset = OneHot.fit_transform(dataset)\n",
        "\n",
        "#Applaying binary encoder for Cholesterol\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Cholesterol'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "#spliting variables into depended and target value\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Applying label encoding to the target variable 'Drug'\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 735,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvxIPVyMhmKp"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVzJWAXIhxoC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
      ],
      "execution_count": 736,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3nS3-6r1i2B",
        "outputId": "4690b842-cab8-4ff2-ee61-57ee6617f624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 737,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[51.     0.     1.    ...  0.     1.    13.597]\n",
            " [36.     0.     1.    ...  0.     1.    16.753]\n",
            " [64.     1.     0.    ...  0.     1.     7.761]\n",
            " ...\n",
            " [49.     1.     0.    ...  1.     0.    11.014]\n",
            " [48.     1.     0.    ...  1.     0.    10.446]\n",
            " [61.     0.     1.    ...  0.     1.    18.043]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dpDLojm1mVG",
        "outputId": "6bfa2231-c075-460b-9e0e-1346dbc44582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 738,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 0 4 0 0 4 1 0 0 4 2 1 2 0 2 4 1 2 0 1 3 0 0 0 3 4 1 4 0 0 4 3 3 0 4 0 4\n",
            " 4 0 4 4 0 4 0 0 0 0 1 0 3 0 0 2 0 0 4 0 0 0 4 4 4 3 3 4 2 4 4 1 0 2 4 0 0\n",
            " 4 1 0 1 1 0 3 0 1 0 0 0 4 2 4 0 2 0 1 0 0 4 0 0 0 0 0 4 1 4 4 0 0 0 4 4 0\n",
            " 1 0 2 0 4 0 4 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbb7i0DH1qui",
        "outputId": "8f57a08f-fb26-4b02-f6e5-c588b30d7131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 739,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[68.     1.     0.     0.     1.     0.     0.     1.    10.291]\n",
            " [34.     1.     0.     0.     0.     1.     0.     1.    22.456]\n",
            " [66.     1.     0.     1.     0.     0.     0.     1.    16.347]\n",
            " [47.     0.     1.     0.     1.     0.     0.     1.    10.067]\n",
            " [39.     1.     0.     0.     0.     1.     0.     1.    15.969]\n",
            " [32.     0.     1.     0.     0.     1.     0.     1.     7.477]\n",
            " [65.     0.     1.     0.     1.     0.     1.     0.    13.769]\n",
            " [67.     1.     0.     0.     0.     1.     1.     0.    10.898]\n",
            " [56.     0.     1.     0.     1.     0.     0.     1.    11.567]\n",
            " [20.     0.     1.     0.     1.     0.     1.     0.    11.686]\n",
            " [50.     0.     1.     0.     0.     1.     0.     1.    12.703]\n",
            " [26.     0.     1.     1.     0.     0.     1.     0.    12.307]\n",
            " [69.     1.     0.     0.     1.     0.     1.     0.    11.455]\n",
            " [72.     0.     1.     0.     1.     0.     1.     0.    14.642]\n",
            " [28.     1.     0.     0.     0.     1.     0.     1.    27.064]\n",
            " [34.     0.     1.     1.     0.     0.     1.     0.    19.199]\n",
            " [58.     0.     1.     1.     0.     0.     1.     0.    14.239]\n",
            " [47.     1.     0.     0.     1.     0.     1.     0.    33.542]\n",
            " [47.     0.     1.     0.     1.     0.     0.     1.    11.767]\n",
            " [37.     0.     1.     0.     1.     0.     1.     0.    12.006]\n",
            " [59.     1.     0.     1.     0.     0.     0.     1.    13.935]\n",
            " [55.     1.     0.     0.     0.     1.     1.     0.     7.261]\n",
            " [25.     1.     0.     0.     0.     1.     0.     1.    19.011]\n",
            " [50.     0.     1.     0.     0.     1.     1.     0.    12.295]\n",
            " [70.     0.     1.     0.     0.     1.     0.     1.    20.489]\n",
            " [41.     0.     1.     0.     0.     1.     1.     0.    22.905]\n",
            " [15.     1.     0.     1.     0.     0.     1.     0.    17.206]\n",
            " [35.     0.     1.     1.     0.     0.     0.     1.    12.894]\n",
            " [20.     1.     0.     1.     0.     0.     1.     0.    35.639]\n",
            " [32.     0.     1.     0.     1.     0.     1.     0.    10.84 ]\n",
            " [32.     0.     1.     1.     0.     0.     1.     0.    10.292]\n",
            " [24.     0.     1.     0.     0.     1.     0.     1.    10.605]\n",
            " [54.     1.     0.     0.     0.     1.     0.     1.    24.658]\n",
            " [42.     0.     1.     1.     0.     0.     0.     1.    21.036]\n",
            " [26.     1.     0.     0.     1.     0.     1.     0.    20.909]\n",
            " [51.     1.     0.     1.     0.     0.     0.     1.    18.295]\n",
            " [38.     0.     1.     1.     0.     0.     1.     0.    11.326]\n",
            " [65.     1.     0.     1.     0.     0.     1.     0.    11.34 ]\n",
            " [69.     0.     1.     0.     0.     1.     0.     1.    10.065]\n",
            " [41.     1.     0.     1.     0.     0.     1.     0.    15.156]\n",
            " [39.     0.     1.     0.     1.     0.     1.     0.    22.697]\n",
            " [41.     1.     0.     0.     1.     0.     0.     1.    11.037]\n",
            " [43.     1.     0.     0.     1.     0.     0.     1.    15.376]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.    19.675]\n",
            " [15.     0.     1.     1.     0.     0.     1.     0.    16.725]\n",
            " [19.     0.     1.     1.     0.     0.     1.     0.    25.969]\n",
            " [23.     1.     0.     0.     1.     0.     0.     1.     7.298]\n",
            " [53.     1.     0.     0.     0.     1.     0.     1.    14.133]\n",
            " [47.     1.     0.     1.     0.     0.     0.     1.    10.403]\n",
            " [28.     0.     1.     0.     1.     0.     0.     1.    13.127]\n",
            " [42.     0.     1.     0.     1.     0.     1.     0.    29.271]\n",
            " [40.     0.     1.     0.     0.     1.     0.     1.    10.103]\n",
            " [18.     0.     1.     1.     0.     0.     0.     1.    37.188]\n",
            " [36.     0.     1.     1.     0.     0.     1.     0.    15.49 ]\n",
            " [40.     1.     0.     1.     0.     0.     0.     1.    27.826]\n",
            " [67.     0.     1.     0.     0.     1.     0.     1.    15.891]\n",
            " [33.     0.     1.     0.     1.     0.     0.     1.    33.486]\n",
            " [68.     1.     0.     1.     0.     0.     0.     1.    11.009]\n",
            " [72.     1.     0.     0.     1.     0.     0.     1.    16.31 ]\n",
            " [35.     1.     0.     0.     0.     1.     1.     0.     7.845]\n",
            " [24.     1.     0.     0.     0.     1.     0.     1.    25.786]\n",
            " [36.     1.     0.     0.     1.     0.     1.     0.    11.424]\n",
            " [53.     0.     1.     1.     0.     0.     1.     0.    12.495]\n",
            " [68.     0.     1.     0.     0.     1.     1.     0.    27.05 ]\n",
            " [23.     0.     1.     1.     0.     0.     0.     1.    25.355]\n",
            " [18.     0.     1.     1.     0.     0.     1.     0.    24.276]\n",
            " [39.     1.     0.     1.     0.     0.     0.     1.     9.664]\n",
            " [47.     1.     0.     0.     1.     0.     0.     1.    10.114]\n",
            " [59.     0.     1.     0.     0.     1.     0.     1.    13.884]\n",
            " [53.     1.     0.     0.     1.     0.     0.     1.    22.963]\n",
            " [61.     0.     1.     1.     0.     0.     0.     1.    25.475]\n",
            " [38.     1.     0.     0.     1.     0.     0.     1.    18.295]\n",
            " [60.     1.     0.     0.     0.     1.     1.     0.    10.091]\n",
            " [42.     1.     0.     0.     1.     0.     0.     1.    20.013]\n",
            " [45.     1.     0.     0.     1.     0.     0.     1.    17.951]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     8.7  ]\n",
            " [67.     1.     0.     0.     0.     1.     1.     0.     9.514]\n",
            " [60.     1.     0.     1.     0.     0.     0.     1.    13.934]\n",
            " [61.     1.     0.     0.     0.     1.     0.     1.     9.443]\n",
            " [37.     0.     1.     1.     0.     0.     0.     1.    13.091]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj1hnFAR1s5w",
        "outputId": "915b1b77-3c9f-4d4f-941c-fc807002d618",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 740,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 0 0 3 0 4 4 4 3 4 4 1 4 4 0 0 2 0 3 4 2 4 0 4 0 0 0 1 0 4 1 4 0 0 0 0 1\n",
            " 2 4 0 0 3 0 0 0 0 3 4 1 3 0 4 0 0 0 0 0 2 0 4 0 4 2 0 0 0 1 3 4 0 0 0 4 0\n",
            " 0 1 4 2 4 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW3c7UYih0hT"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fQlDPKCh8sc"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 741,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syrnD1Op2BSR",
        "outputId": "1ad22ed2-aa60-4c60-93a5-92f0f3634a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 742,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.39037891 -1.06904497  1.06904497 ... -1.05131497  1.05131497\n",
            "  -0.30709991]\n",
            " [-0.49909203 -1.06904497  1.06904497 ... -1.05131497  1.05131497\n",
            "   0.12482349]\n",
            " [ 1.16125373  0.93541435 -0.93541435 ... -1.05131497  1.05131497\n",
            "  -1.10580235]\n",
            " ...\n",
            " [ 0.27178279  0.93541435 -0.93541435 ...  0.95118973 -0.95118973\n",
            "  -0.66060375]\n",
            " [ 0.21248473  0.93541435 -0.93541435 ...  0.95118973 -0.95118973\n",
            "  -0.73833901]\n",
            " [ 0.98335954 -1.06904497  1.06904497 ... -1.05131497  1.05131497\n",
            "   0.30137012]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUd6iBRp2C3L",
        "outputId": "61e3da45-5049-44d5-c848-97f9fd98658d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 743,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.39844598  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.75955198]\n",
            " [-0.61768816  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  0.90532384]\n",
            " [ 1.27984986  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  0.0692592 ]\n",
            " [ 0.15318666 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.79020814]\n",
            " [-0.32119784  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  0.01752693]\n",
            " [-0.73628428 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -1.14466998]\n",
            " [ 1.22055179 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.28356035]\n",
            " [ 1.33914792  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973 -0.67647926]\n",
            " [ 0.68686923 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.58492135]\n",
            " [-1.44786104 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.56863527]\n",
            " [ 0.33108085 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.42945083]\n",
            " [-1.09207266 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.48364654]\n",
            " [ 1.45774405  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.60024943]\n",
            " [ 1.63563823 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.16408345]\n",
            " [-0.97347653  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  1.53596484]\n",
            " [-0.61768816 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973  0.4595778 ]\n",
            " [ 0.80546535 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.21923716]\n",
            " [ 0.15318666  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973  2.42253003]\n",
            " [ 0.15318666 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.55754978]\n",
            " [-0.43979397 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.52484075]\n",
            " [ 0.86476342  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.26084195]\n",
            " [ 0.62757117  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973 -1.17423128]\n",
            " [-1.15137072  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  0.43384853]\n",
            " [ 0.33108085 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973 -0.48528883]\n",
            " [ 1.51704211 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  0.63612444]\n",
            " [-0.20260171 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973  0.96677302]\n",
            " [-1.74435135  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973  0.1868201 ]\n",
            " [-0.55839009 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.40331098]\n",
            " [-1.44786104  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973  2.70952096]\n",
            " [-0.73628428 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.68441701]\n",
            " [-0.73628428 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.75941512]\n",
            " [-1.21066878 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.71657861]\n",
            " [ 0.5682731   0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  1.20668484]\n",
            " [-0.14330365 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  0.71098569]\n",
            " [-1.09207266  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973  0.69360474]\n",
            " [ 0.39037891  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  0.3358583 ]\n",
            " [-0.3804959  -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.6179041 ]\n",
            " [ 1.22055179  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.61598809]\n",
            " [ 1.45774405 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.79048185]\n",
            " [-0.20260171  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.09373851]\n",
            " [-0.32119784 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973  0.93830659]\n",
            " [-0.20260171  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.65745602]\n",
            " [-0.08400559  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.06362978]\n",
            " [-0.97347653 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  0.52472214]\n",
            " [-1.74435135 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973  0.12099147]\n",
            " [-1.5071591  -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973  1.38610549]\n",
            " [-1.26996685  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -1.16916754]\n",
            " [ 0.50897504  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.23374409]\n",
            " [ 0.15318666  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.7442239 ]\n",
            " [-0.97347653 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.3714231 ]\n",
            " [-0.14330365 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973  1.83801013]\n",
            " [-0.26189978 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.78528125]\n",
            " [-1.56645716 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  2.92151378]\n",
            " [-0.49909203 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.04802798]\n",
            " [-0.26189978  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  1.64025053]\n",
            " [ 1.33914792 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  0.00685202]\n",
            " [-0.67698622 -1.06904497  1.06904497 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497  2.41486599]\n",
            " [ 1.39844598  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.66128804]\n",
            " [ 1.63563823  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497  0.06419546]\n",
            " [-0.55839009  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973 -1.09430629]\n",
            " [-1.21066878  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497  1.3610605 ]\n",
            " [-0.49909203  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.60449203]\n",
            " [ 0.50897504 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.45791726]\n",
            " [ 1.39844598 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973  1.53404883]\n",
            " [-1.26996685 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  1.30207477]\n",
            " [-1.56645716 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973  1.15440514]\n",
            " [-0.32119784  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.84536185]\n",
            " [ 0.15318666  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.78377582]\n",
            " [ 0.86476342 -1.06904497  1.06904497 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.2678217 ]\n",
            " [ 0.50897504  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497  0.97471078]\n",
            " [ 0.98335954 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497  1.31849771]\n",
            " [-0.3804959   0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497  0.3358583 ]\n",
            " [ 0.92406148  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973 -0.78692355]\n",
            " [-0.14330365  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497  0.5709801 ]\n",
            " [ 0.03459054  0.93541435 -0.93541435 -0.81649658  1.46897745 -0.62876771\n",
            "  -1.05131497  1.05131497  0.2887792 ]\n",
            " [ 0.27178279  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "   0.95118973 -0.95118973 -0.97729283]\n",
            " [ 1.33914792  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "   0.95118973 -0.95118973 -0.86589053]\n",
            " [ 0.92406148  0.93541435 -0.93541435  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.26097881]\n",
            " [ 0.98335954  0.93541435 -0.93541435 -0.81649658 -0.68074565  1.59041245\n",
            "  -1.05131497  1.05131497 -0.87560744]\n",
            " [-0.43979397 -1.06904497  1.06904497  1.22474487 -0.68074565 -0.62876771\n",
            "  -1.05131497  1.05131497 -0.37634998]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb6jCOCQiAmP"
      },
      "source": [
        "## Training the SVM model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0pFVAmciHQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ec0456ed-fa33-4557-ae64-083ab7deac47"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 744,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-33 {color: black;background-color: white;}#sk-container-id-33 pre{padding: 0;}#sk-container-id-33 div.sk-toggleable {background-color: white;}#sk-container-id-33 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-33 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-33 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-33 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-33 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-33 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-33 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-33 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-33 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-33 div.sk-item {position: relative;z-index: 1;}#sk-container-id-33 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-33 div.sk-item::before, #sk-container-id-33 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-33 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-33 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-33 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-33 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-33 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-33 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-33 div.sk-label-container {text-align: center;}#sk-container-id-33 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-33 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 744
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKYVQH-l5NpE"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6VMTb2O4hwM",
        "outputId": "96845c14-c328-47b5-db17-eb9771023dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 745,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 3]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [3 3]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [0 4]\n",
            " [4 4]\n",
            " [3 3]\n",
            " [4 4]\n",
            " [4 4]\n",
            " [1 1]\n",
            " [4 4]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 2]\n",
            " [0 0]\n",
            " [3 3]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [1 1]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [3 3]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [3 3]\n",
            " [0 4]\n",
            " [1 1]\n",
            " [3 3]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [3 3]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [4 4]\n",
            " [2 2]\n",
            " [4 4]\n",
            " [1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Hwj34ziWQW"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6bpZwUiiXic",
        "outputId": "23340b78-89f4-4656-f48c-94a7093dc6f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 746,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[37  0  0  0  0]\n",
            " [ 0  8  0  0  0]\n",
            " [ 1  0  5  0  0]\n",
            " [ 0  0  0  8  0]\n",
            " [ 4  0  0  0 17]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9375"
            ]
          },
          "metadata": {},
          "execution_count": 746
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M26H8mYb-xcP"
      },
      "source": [
        "# Simple Support Vector Machine (SVM) with cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72M_zqp9-xcY"
      },
      "source": [
        "## Importing the dataset and encoding categorical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shMuTVSj-xcY"
      },
      "source": [
        "dataset = pd.read_csv('drug200.csv')\n",
        "\n",
        "# Applying the binary encoder for SEX\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Sex'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "# Applying the OneHot encoder for blood pressure\n",
        "OneHot = ce.OneHotEncoder(cols=['BP'])\n",
        "dataset = OneHot.fit_transform(dataset)\n",
        "\n",
        "#Applaying binary encoder for Cholesterol\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Cholesterol'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "#spliting variables into depended and target value\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Applying label encoding to the target variable 'Drug'\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 747,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0beFgGBh-xcY"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHIm9Lk2-xcY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
      ],
      "execution_count": 748,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "bfcd141d-ad05-4f92-fd88-c25b724ec745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwSFT_BO-xcZ"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 749,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[50.     1.     0.    ...  1.     0.    15.79 ]\n",
            " [35.     1.     0.    ...  1.     0.     9.17 ]\n",
            " [42.     1.     0.    ...  1.     0.    12.766]\n",
            " ...\n",
            " [23.     1.     0.    ...  0.     1.    31.686]\n",
            " [20.     0.     1.    ...  1.     0.    11.686]\n",
            " [74.     1.     0.    ...  1.     0.    11.939]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "506f83f9-22c4-40a8-ec53-19ebfc7d0ebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaKflWsF-xcZ"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 750,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 4 1 0 0 4 0 0 0 0 4 3 4 2 4 0 4 0 4 4 0 0 1 0 0 0 4 3 2 0 4 4 0 0 0 4 3\n",
            " 3 0 2 4 0 0 0 4 2 1 0 0 4 0 4 0 1 4 4 3 2 0 4 3 0 3 3 4 0 0 0 0 4 4 4 0 0\n",
            " 4 0 1 4 0 0 1 0 1 4 2 4 0 0 0 1 0 1 2 0 1 0 0 0 0 0 2 0 0 4 0 0 0 3 3 4 0\n",
            " 0 0 4 0 3 1 0 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "39ddd951-50fd-40b2-920f-b515676fbd7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcntpxXF-xcZ"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 751,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[26.     0.     1.     1.     0.     0.     1.     0.    12.307]\n",
            " [30.     0.     1.     0.     0.     1.     0.     1.    10.443]\n",
            " [36.     0.     1.     1.     0.     0.     1.     0.    15.49 ]\n",
            " [24.     0.     1.     0.     0.     1.     0.     1.    10.605]\n",
            " [22.     1.     0.     0.     0.     1.     0.     1.    11.953]\n",
            " [60.     1.     0.     1.     0.     0.     1.     0.     8.621]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     6.269]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    17.069]\n",
            " [64.     0.     1.     0.     1.     0.     1.     0.    25.741]\n",
            " [37.     0.     1.     1.     0.     0.     0.     1.    13.091]\n",
            " [15.     1.     0.     0.     0.     1.     0.     1.     9.084]\n",
            " [69.     1.     0.     0.     1.     0.     1.     0.    11.455]\n",
            " [40.     0.     1.     0.     0.     1.     0.     1.    10.103]\n",
            " [60.     1.     0.     1.     0.     0.     0.     1.    13.934]\n",
            " [50.     0.     1.     0.     0.     1.     1.     0.    17.211]\n",
            " [25.     1.     0.     0.     0.     1.     0.     1.    19.011]\n",
            " [49.     1.     0.     0.     1.     0.     1.     0.    11.014]\n",
            " [45.     1.     0.     0.     1.     0.     0.     1.    17.951]\n",
            " [74.     0.     1.     0.     1.     0.     0.     1.    20.942]\n",
            " [64.     1.     0.     1.     0.     0.     1.     0.    20.932]\n",
            " [68.     0.     1.     1.     0.     0.     1.     0.    10.189]\n",
            " [43.     1.     0.     0.     0.     1.     1.     0.    12.859]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.    12.879]\n",
            " [58.     0.     1.     1.     0.     0.     0.     1.    19.416]\n",
            " [20.     0.     1.     1.     0.     0.     0.     1.    11.262]\n",
            " [38.     0.     1.     1.     0.     0.     1.     0.    11.326]\n",
            " [69.     0.     1.     0.     0.     1.     0.     1.    10.065]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     8.7  ]\n",
            " [43.     1.     0.     1.     0.     0.     0.     1.    13.972]\n",
            " [41.     1.     0.     1.     0.     0.     1.     0.    15.156]\n",
            " [32.     1.     0.     1.     0.     0.     1.     0.     9.445]\n",
            " [23.     1.     0.     0.     0.     1.     0.     1.    12.26 ]\n",
            " [50.     1.     0.     1.     0.     0.     0.     1.     7.49 ]\n",
            " [23.     1.     0.     0.     0.     1.     1.     0.    14.02 ]\n",
            " [72.     1.     0.     1.     0.     0.     1.     0.     9.677]\n",
            " [58.     1.     0.     1.     0.     0.     0.     1.    18.991]\n",
            " [74.     1.     0.     1.     0.     0.     0.     1.     9.567]\n",
            " [51.     1.     0.     1.     0.     0.     0.     1.    18.295]\n",
            " [61.     0.     1.     0.     1.     0.     1.     0.     7.34 ]\n",
            " [47.     0.     1.     0.     1.     0.     0.     1.    11.767]\n",
            " [68.     0.     1.     0.     0.     1.     1.     0.    27.05 ]\n",
            " [70.     1.     0.     1.     0.     0.     0.     1.     9.849]\n",
            " [37.     0.     1.     0.     1.     0.     1.     0.    12.006]\n",
            " [24.     1.     0.     0.     0.     1.     0.     1.    25.786]\n",
            " [36.     1.     0.     0.     1.     0.     1.     0.    11.424]\n",
            " [29.     0.     1.     1.     0.     0.     0.     1.    29.45 ]\n",
            " [17.     1.     0.     0.     0.     1.     1.     0.    10.832]\n",
            " [35.     0.     1.     1.     0.     0.     0.     1.    12.894]\n",
            " [72.     1.     0.     0.     1.     0.     0.     1.     6.769]\n",
            " [38.     1.     0.     0.     1.     0.     0.     1.    18.295]\n",
            " [28.     0.     1.     0.     1.     0.     0.     1.    13.127]\n",
            " [70.     0.     1.     0.     0.     1.     0.     1.    20.489]\n",
            " [39.     1.     0.     0.     0.     1.     0.     1.    15.969]\n",
            " [63.     1.     0.     0.     0.     1.     0.     1.    25.917]\n",
            " [32.     0.     1.     1.     0.     0.     1.     0.    10.292]\n",
            " [57.     0.     1.     1.     0.     0.     1.     0.     9.945]\n",
            " [28.     0.     1.     1.     0.     0.     1.     0.    18.809]\n",
            " [56.     1.     0.     0.     0.     1.     0.     1.     8.966]\n",
            " [18.     0.     1.     1.     0.     0.     0.     1.    37.188]\n",
            " [58.     0.     1.     0.     1.     0.     0.     1.    26.645]\n",
            " [62.     1.     0.     0.     1.     0.     1.     0.    27.183]\n",
            " [61.     0.     1.     0.     1.     0.     0.     1.    18.043]\n",
            " [22.     1.     0.     0.     1.     0.     0.     1.     8.151]\n",
            " [67.     1.     0.     0.     1.     0.     1.     0.    20.693]\n",
            " [74.     1.     0.     1.     0.     0.     1.     0.    15.436]\n",
            " [58.     0.     1.     1.     0.     0.     1.     0.    14.239]\n",
            " [47.     1.     0.     1.     0.     0.     0.     1.    10.403]\n",
            " [34.     0.     1.     0.     1.     0.     1.     0.    12.923]\n",
            " [15.     1.     0.     1.     0.     0.     1.     0.    17.206]\n",
            " [57.     1.     0.     0.     1.     0.     1.     0.    19.128]\n",
            " [67.     1.     0.     0.     0.     1.     1.     0.     9.514]\n",
            " [19.     0.     1.     1.     0.     0.     1.     0.    25.969]\n",
            " [49.     0.     1.     0.     0.     1.     1.     0.     9.381]\n",
            " [22.     1.     0.     1.     0.     0.     1.     0.    28.294]\n",
            " [23.     1.     0.     0.     1.     0.     0.     1.     7.298]\n",
            " [66.     0.     1.     0.     0.     1.     1.     0.     8.107]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.    19.675]\n",
            " [39.     0.     1.     0.     0.     1.     1.     0.    17.225]\n",
            " [51.     0.     1.     0.     1.     0.     1.     0.    23.003]\n",
            " [61.     1.     0.     0.     0.     1.     0.     1.     9.443]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "45a7184d-d7e7-43ba-869e-e4d2960a6753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6OJytYO-xcZ"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 752,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 0 4 4 2 1 0 0 1 4 4 4 2 0 0 4 0 0 0 2 4 4 0 1 1 4 1 1 0 1 4 1 4 2 0 2\n",
            " 0 4 3 0 2 4 0 4 0 4 1 3 0 3 0 0 0 1 2 0 4 0 0 0 0 3 0 0 2 1 4 0 0 4 0 4 0\n",
            " 3 4 0 0 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWl6Ua8N-xca"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MyjrtPI-xca"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 753,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "63368a3a-d6ab-472b-e42d-f160eb3d2357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75xPX5-k-xca"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 754,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.39974131  0.98346994 -0.98346994 ...  1.05131497 -1.05131497\n",
            "  -0.1324063 ]\n",
            " [-0.55708629  0.98346994 -0.98346994 ...  1.05131497 -1.05131497\n",
            "  -1.00040786]\n",
            " [-0.11056675  0.98346994 -0.98346994 ...  1.05131497 -1.05131497\n",
            "  -0.52890731]\n",
            " ...\n",
            " [-1.32254838  0.98346994 -0.98346994 ... -0.95118973  0.95118973\n",
            "   1.9518464 ]\n",
            " [-1.5139139  -1.0168079   1.0168079  ...  1.05131497 -1.05131497\n",
            "  -0.67051482]\n",
            " [ 1.93066548  0.98346994 -0.98346994 ...  1.05131497 -1.05131497\n",
            "  -0.63734195]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "02de9ae4-5f3d-4a27-9ec3-ac7d7b383feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdo9jSMl-xca"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 755,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.13118286 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.5890905 ]\n",
            " [-0.87602883 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.83349457]\n",
            " [-0.49329779 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.17174171]\n",
            " [-1.25875987 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.81225344]\n",
            " [-1.38633689  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.6355063 ]\n",
            " [ 1.03762638  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -1.07239168]\n",
            " [ 0.3359528   0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -1.38078136]\n",
            " [-0.81224032  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497  0.0352937 ]\n",
            " [ 1.29278041 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497  1.17234953]\n",
            " [-0.42950928 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.48629394]\n",
            " [-1.83285643  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -1.01168401]\n",
            " [ 1.61172294  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.70080309]\n",
            " [-0.23814376 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.87807471]\n",
            " [ 1.03762638  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.37576142]\n",
            " [ 0.39974131 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497  0.05391247]\n",
            " [-1.19497136  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973  0.28992498]\n",
            " [ 0.3359528   0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.75862616]\n",
            " [ 0.08079878  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973  0.15093983]\n",
            " [ 1.93066548 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973  0.54311395]\n",
            " [ 1.29278041  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497  0.54180277]\n",
            " [ 1.54793444 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.86679856]\n",
            " [-0.04677824  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497 -0.51671333]\n",
            " [-1.00360584 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.51409097]\n",
            " [ 0.91004937 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973  0.34302779]\n",
            " [-1.5139139  -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.72610888]\n",
            " [-0.36572077 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.71771732]\n",
            " [ 1.61172294 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.8830572 ]\n",
            " [ 0.3359528   0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -1.06203335]\n",
            " [-0.04677824  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.37077893]\n",
            " [-0.17435525  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.21553515]\n",
            " [-0.74845182  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.96435039]\n",
            " [-1.32254838  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.59525305]\n",
            " [ 0.39974131  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -1.2206862 ]\n",
            " [-1.32254838  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497 -0.36448526]\n",
            " [ 1.80308846  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.933931  ]\n",
            " [ 0.91004937  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973  0.28730262]\n",
            " [ 1.93066548  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.94835399]\n",
            " [ 0.46352982  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973  0.19604445]\n",
            " [ 1.10141489 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497 -1.24035391]\n",
            " [ 0.20837579 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.65989426]\n",
            " [ 1.54793444 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497  1.34398307]\n",
            " [ 1.67551145  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.9113787 ]\n",
            " [-0.42950928 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.62855704]\n",
            " [-1.25875987  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973  1.17824984]\n",
            " [-0.49329779  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.70486775]\n",
            " [-0.93981734 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973  1.65866642]\n",
            " [-1.70527942  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497 -0.78248964]\n",
            " [-0.55708629 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.5121242 ]\n",
            " [ 1.80308846  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973 -1.31522233]\n",
            " [-0.36572077  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973  0.19604445]\n",
            " [-1.00360584 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.48157369]\n",
            " [ 1.67551145 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973  0.48371747]\n",
            " [-0.30193227  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.10893616]\n",
            " [ 1.2289919   0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973  1.19542631]\n",
            " [-0.74845182 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.8532934 ]\n",
            " [ 0.84626086 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.89879136]\n",
            " [-1.00360584 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497  0.26343913]\n",
            " [ 0.78247235  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -1.02715594]\n",
            " [-1.64149091 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973  2.67325797]\n",
            " [ 0.91004937 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973  1.29088026]\n",
            " [ 1.16520339  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497  1.36142177]\n",
            " [ 1.10141489 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973  0.1630027 ]\n",
            " [-1.38633689  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973 -1.13401716]\n",
            " [ 1.48414593  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497  0.51046556]\n",
            " [ 1.93066548  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.17882209]\n",
            " [ 0.91004937 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.33577041]\n",
            " [ 0.20837579  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "  -0.95118973  0.95118973 -0.83873929]\n",
            " [-0.6208748  -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497 -0.50832178]\n",
            " [-1.83285643  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497  0.05325688]\n",
            " [ 0.84626086  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497  0.30526579]\n",
            " [ 1.48414593  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497 -0.95530325]\n",
            " [-1.57770241 -1.0168079   1.0168079   1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497  1.20224445]\n",
            " [ 0.3359528  -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497 -0.97274195]\n",
            " [-1.38633689  0.98346994 -0.98346994  1.33816952 -0.74728947 -0.62876771\n",
            "   1.05131497 -1.05131497  1.50709394]\n",
            " [-1.32254838  0.98346994 -0.98346994 -0.74728947  1.33816952 -0.62876771\n",
            "  -0.95118973  0.95118973 -1.24586087]\n",
            " [ 1.42035742 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497 -1.13978636]\n",
            " [-1.00360584 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973  0.37698737]\n",
            " [-0.30193227 -1.0168079   1.0168079  -0.74728947 -0.74728947  1.59041245\n",
            "   1.05131497 -1.05131497  0.05574812]\n",
            " [ 0.46352982 -1.0168079   1.0168079  -0.74728947  1.33816952 -0.62876771\n",
            "   1.05131497 -1.05131497  0.81334828]\n",
            " [ 1.10141489  0.98346994 -0.98346994 -0.74728947 -0.74728947  1.59041245\n",
            "  -0.95118973  0.95118973 -0.96461263]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjbQTCK9-xca"
      },
      "source": [
        "## Creating the SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRc_uc7G-xcb"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state=0)"
      ],
      "execution_count": 756,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UqqcZ8T-xcb"
      },
      "source": [
        "## Applying Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iWfSZic-xcb"
      },
      "source": [
        "# Define the k-fold cross-validator (k=5)\n",
        "kf = KFold(n_splits=2, shuffle=True)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(classifier, X, y, cv=kf)"
      ],
      "execution_count": 757,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yo1d4g--xcb"
      },
      "source": [
        "## Printing Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "52459248-908d-4048-b9d9-0f8d14bf92c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN1RK-Ki-xcb"
      },
      "source": [
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())"
      ],
      "execution_count": 758,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.98 0.99]\n",
            "Mean CV Score: 0.985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Triying different n_splits"
      ],
      "metadata": {
        "id": "J-wT7NlzAoS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the k-fold cross-validator (k=10)\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(classifier, X, y, cv=kf)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gXhTQmnAy5Z",
        "outputId": "fde48117-86df-434a-fee0-be87ffc96421"
      },
      "execution_count": 759,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [1.   1.   0.95 0.95 1.   1.   1.   1.   1.   1.  ]\n",
            "Mean CV Score: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the k-fold cross-validator (k=15)\n",
        "kf = KFold(n_splits=15, shuffle=True)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(classifier, X, y, cv=kf)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5pj8hkxA6B3",
        "outputId": "8b2bb2fd-8ad8-4a16-eeab-03a3f4c6ede2"
      },
      "execution_count": 760,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.92857143 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         0.92307692\n",
            " 1.         1.         1.        ]\n",
            "Mean CV Score: 0.9901098901098901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the k-fold cross-validator (k=25)\n",
        "kf = KFold(n_splits=25, shuffle=True)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(classifier, X, y, cv=kf)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hGVmM9iBHFo",
        "outputId": "245587c6-48be-43ee-f0f9-c61bccbf4bd2"
      },
      "execution_count": 761,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.\n",
            " 1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    1.    0.875\n",
            " 0.875]\n",
            "Mean CV Score: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0LSkk_TB11g"
      },
      "source": [
        "# Simple Support Vector Machine (SVM) with PCA Applayied"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdBuXW8BB11q"
      },
      "source": [
        "## Importing the dataset and encoding categorical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTzRh7kGB11q"
      },
      "source": [
        "dataset = pd.read_csv('drug200.csv')\n",
        "\n",
        "# Applying the binary encoder for SEX\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Sex'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "# Applying the OneHot encoder for blood pressure\n",
        "OneHot = ce.OneHotEncoder(cols=['BP'])\n",
        "dataset = OneHot.fit_transform(dataset)\n",
        "\n",
        "#Applaying binary encoder for Cholesterol\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Cholesterol'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "#spliting variables into depended and target value\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Applying label encoding to the target variable 'Drug'\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 762,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxSQQ9DeB11q"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyJPsBJqB11q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
      ],
      "execution_count": 763,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "1879a2d7-ec97-4e03-f16b-299c77e2fdc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7rMEKp2B11r"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 764,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[47.     1.     0.    ...  0.     1.    13.093]\n",
            " [24.     0.     1.    ...  0.     1.    10.605]\n",
            " [28.     0.     1.    ...  0.     1.    12.879]\n",
            " ...\n",
            " [54.     1.     0.    ...  0.     1.    24.658]\n",
            " [28.     0.     1.    ...  1.     0.    18.809]\n",
            " [35.     0.     1.    ...  0.     1.    12.894]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "97715f8a-8538-408b-d66d-e3e348ea1a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOVji8YGB11r"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 765,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 4 3 4 3 0 4 3 0 1 4 0 4 0 0 0 0 0 0 0 0 4 0 0 1 2 4 4 3 2 0 0 0 4 4 0\n",
            " 4 4 3 2 4 2 0 0 0 2 0 0 0 1 0 0 0 0 1 0 2 1 0 2 0 2 4 4 4 0 4 0 4 1 3 4 0\n",
            " 0 0 4 0 4 0 4 2 0 0 0 0 4 4 0 3 4 0 0 2 0 0 4 0 0 0 4 2 3 1 0 0 4 1 1 1 4\n",
            " 3 0 4 0 4 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "f667be2d-3090-4538-b1da-20f89d73c638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txGXuIBFB11r"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 766,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[66.     1.     0.     1.     0.     0.     0.     1.    16.347]\n",
            " [36.     0.     1.     0.     0.     1.     0.     1.    16.753]\n",
            " [49.     0.     1.     0.     0.     1.     0.     1.    16.275]\n",
            " [57.     0.     1.     0.     0.     1.     1.     0.    25.893]\n",
            " [19.     0.     1.     1.     0.     0.     1.     0.    25.969]\n",
            " [74.     1.     0.     1.     0.     0.     1.     0.    15.436]\n",
            " [21.     0.     1.     1.     0.     0.     1.     0.    28.632]\n",
            " [24.     1.     0.     0.     0.     1.     0.     1.    25.786]\n",
            " [46.     1.     0.     0.     0.     1.     1.     0.     7.285]\n",
            " [63.     1.     0.     0.     0.     1.     0.     1.    25.917]\n",
            " [18.     0.     1.     0.     0.     1.     1.     0.     8.75 ]\n",
            " [58.     0.     1.     0.     1.     0.     0.     1.    38.247]\n",
            " [42.     1.     0.     0.     1.     0.     0.     1.    20.013]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.    19.675]\n",
            " [36.     1.     0.     0.     1.     0.     1.     0.    11.424]\n",
            " [37.     1.     0.     0.     1.     0.     1.     0.    16.724]\n",
            " [68.     0.     1.     1.     0.     0.     1.     0.    10.189]\n",
            " [22.     1.     0.     0.     0.     1.     0.     1.    11.953]\n",
            " [26.     0.     1.     0.     1.     0.     0.     1.    14.16 ]\n",
            " [28.     0.     1.     0.     1.     0.     0.     1.    13.127]\n",
            " [32.     0.     1.     0.     1.     0.     0.     1.     9.712]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     6.269]\n",
            " [58.     0.     1.     1.     0.     0.     1.     0.    14.239]\n",
            " [48.     1.     0.     1.     0.     0.     1.     0.    10.446]\n",
            " [45.     1.     0.     0.     1.     0.     0.     1.    17.951]\n",
            " [50.     0.     1.     0.     0.     1.     1.     0.    17.211]\n",
            " [32.     1.     0.     1.     0.     0.     1.     0.     9.445]\n",
            " [20.     0.     1.     1.     0.     0.     0.     1.    11.262]\n",
            " [72.     0.     1.     0.     1.     0.     1.     0.    14.642]\n",
            " [23.     0.     1.     1.     0.     0.     0.     1.    25.355]\n",
            " [26.     0.     1.     1.     0.     0.     1.     0.    12.307]\n",
            " [41.     0.     1.     0.     1.     0.     1.     0.    18.739]\n",
            " [39.     0.     1.     0.     0.     1.     1.     0.     9.709]\n",
            " [50.     0.     1.     0.     0.     1.     0.     1.    12.703]\n",
            " [40.     0.     1.     0.     0.     1.     0.     1.    10.103]\n",
            " [39.     1.     0.     1.     0.     0.     0.     1.     9.664]\n",
            " [52.     1.     0.     0.     0.     1.     0.     1.     9.894]\n",
            " [74.     1.     0.     1.     0.     0.     0.     1.     9.567]\n",
            " [60.     1.     0.     0.     0.     1.     1.     0.    10.091]\n",
            " [29.     1.     0.     1.     0.     0.     0.     1.    12.856]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    17.069]\n",
            " [66.     0.     1.     0.     0.     1.     1.     0.     8.107]\n",
            " [68.     0.     1.     0.     0.     1.     1.     0.    27.05 ]\n",
            " [47.     1.     0.     0.     1.     0.     1.     0.    30.568]\n",
            " [33.     0.     1.     0.     1.     0.     0.     1.    33.486]\n",
            " [43.     1.     0.     1.     0.     0.     0.     1.    13.972]\n",
            " [47.     1.     0.     0.     1.     0.     0.     1.    10.114]\n",
            " [53.     1.     0.     0.     0.     1.     0.     1.    14.133]\n",
            " [59.     0.     1.     0.     0.     1.     0.     1.    13.884]\n",
            " [34.     1.     0.     1.     0.     0.     0.     1.    18.703]\n",
            " [53.     0.     1.     1.     0.     0.     1.     0.    12.495]\n",
            " [50.     1.     0.     0.     0.     1.     1.     0.    15.79 ]\n",
            " [74.     1.     0.     0.     1.     0.     1.     0.    11.939]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    11.871]\n",
            " [51.     0.     1.     0.     1.     0.     1.     0.    23.003]\n",
            " [43.     1.     0.     0.     1.     0.     0.     1.    15.376]\n",
            " [56.     0.     1.     0.     1.     0.     0.     1.    11.567]\n",
            " [49.     0.     1.     0.     0.     1.     1.     0.     9.381]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.     7.798]\n",
            " [69.     0.     1.     0.     0.     1.     0.     1.    10.065]\n",
            " [59.     1.     0.     1.     0.     0.     0.     1.    13.935]\n",
            " [36.     0.     1.     1.     0.     0.     0.     1.    11.198]\n",
            " [56.     1.     0.     0.     0.     1.     0.     1.     8.966]\n",
            " [60.     1.     0.     0.     0.     1.     0.     1.    15.171]\n",
            " [26.     0.     1.     1.     0.     0.     1.     0.    19.161]\n",
            " [37.     0.     1.     1.     0.     0.     0.     1.    13.091]\n",
            " [45.     1.     0.     0.     1.     0.     1.     0.    10.017]\n",
            " [22.     1.     0.     1.     0.     0.     1.     0.    28.294]\n",
            " [42.     0.     1.     0.     1.     0.     1.     0.    29.271]\n",
            " [73.     0.     1.     0.     0.     1.     0.     1.    19.221]\n",
            " [50.     0.     1.     0.     0.     1.     1.     0.    12.295]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    11.227]\n",
            " [15.     0.     1.     1.     0.     0.     1.     0.    16.725]\n",
            " [23.     1.     0.     0.     0.     1.     1.     0.    14.02 ]\n",
            " [41.     1.     0.     1.     0.     0.     1.     0.    15.156]\n",
            " [67.     0.     1.     0.     0.     1.     0.     1.    15.891]\n",
            " [43.     1.     0.     0.     1.     0.     1.     0.    19.368]\n",
            " [74.     0.     1.     0.     1.     0.     0.     1.    20.942]\n",
            " [59.     0.     1.     0.     1.     0.     0.     1.    10.444]\n",
            " [39.     1.     0.     0.     1.     0.     1.     0.    13.938]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "96297b0d-485d-42a7-cfc2-8f74c6ff3069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqmYkVv1B11r"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 767,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 4 0 4 0 0 0 4 0 2 4 3 3 3 1 2 1 0 0 1 1 4 0 1 0 4 4 4 1 4\n",
            " 2 4 1 0 4 0 0 0 1 3 4 4 0 2 0 4 1 0 0 3 4 4 4 2 1 4 0 0 1 4 0 0 0 4 1 0 4\n",
            " 0 0 0 0 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpMLX-GRB11r"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xckrflrkB11r"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 768,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "2e5f3da9-9e99-49b5-8ab3-68673f2a47d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX4BLMPVB11r"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 769,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.17629875  0.90453403 -0.90453403 ... -0.95118973  0.95118973\n",
            "  -0.42941879]\n",
            " [-1.18668316 -1.1055416   1.1055416  ... -0.95118973  0.95118973\n",
            "  -0.75789009]\n",
            " [-0.94964283 -1.1055416   1.1055416  ... -0.95118973  0.95118973\n",
            "  -0.45767155]\n",
            " ...\n",
            " [ 0.59111933  0.90453403 -0.90453403 ... -0.95118973  0.95118973\n",
            "   1.09741825]\n",
            " [-0.94964283 -1.1055416   1.1055416  ...  1.05131497 -1.05131497\n",
            "   0.32522025]\n",
            " [-0.53482225 -1.1055416   1.1055416  ... -0.95118973  0.95118973\n",
            "  -0.45569122]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "778b32f3-dede-4fe1-edfe-09fa883c1a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6lQi-A_B11r"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 770,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.30224032e+00  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   1.81530561e-04]\n",
            " [-4.75562166e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "   5.37825543e-02]\n",
            " [ 2.94818913e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -9.32406971e-03]\n",
            " [ 7.68899577e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "   1.26046570e+00]\n",
            " [-1.48298358e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   1.27049939e+00]\n",
            " [ 1.77632099e+00  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -1.20090717e-01]\n",
            " [-1.36446341e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   1.62207458e+00]\n",
            " [-1.18668316e+00  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "   1.24633932e+00]\n",
            " [ 1.17038664e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -1.19620388e+00]\n",
            " [ 1.12446007e+00  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "   1.26363423e+00]\n",
            " [-1.54224366e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -1.00279132e+00]\n",
            " [ 8.28159660e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   2.89146828e+00]\n",
            " [-1.20001668e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   4.84175011e-01]\n",
            " [-9.49642830e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "   4.39551498e-01]\n",
            " [-4.75562166e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -6.49763888e-01]\n",
            " [-4.16302083e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   4.99539097e-02]\n",
            " [ 1.42076049e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -8.12811337e-01]\n",
            " [-1.30520333e+00  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -5.79924130e-01]\n",
            " [-1.06816300e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -2.88551078e-01]\n",
            " [-9.49642830e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -4.24930037e-01]\n",
            " [-7.12602498e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -8.75785938e-01]\n",
            " [ 2.94818913e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -1.33033846e+00]\n",
            " [ 8.28159660e-01 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -2.78121322e-01]\n",
            " [ 2.35558830e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -7.78881625e-01]\n",
            " [ 5.77785809e-02  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   2.11945181e-01]\n",
            " [ 3.54078996e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "   1.14248734e-01]\n",
            " [-7.12602498e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -9.11035873e-01]\n",
            " [-1.42372349e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -6.71151488e-01]\n",
            " [ 1.65780082e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -2.24916365e-01]\n",
            " [-1.24594325e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   1.18943774e+00]\n",
            " [-1.06816300e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -5.33188262e-01]\n",
            " [-1.79261751e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   3.15978695e-01]\n",
            " [-2.97781917e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -8.76182005e-01]\n",
            " [ 3.54078996e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -4.80907461e-01]\n",
            " [-2.38521834e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -8.24165248e-01]\n",
            " [-2.97781917e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -8.82123005e-01]\n",
            " [ 4.72599162e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -8.51757893e-01]\n",
            " [ 1.77632099e+00  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -8.94929161e-01]\n",
            " [ 9.46679826e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -8.25749515e-01]\n",
            " [-8.90382747e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -4.60708060e-01]\n",
            " [-7.71862581e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   9.55015777e-02]\n",
            " [ 1.30224032e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -1.08768161e+00]\n",
            " [ 1.42076049e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "   1.41321541e+00]\n",
            " [ 1.76298747e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   1.87766961e+00]\n",
            " [-6.53342415e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   2.26291046e+00]\n",
            " [-6.07415851e-02  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -3.13371256e-01]\n",
            " [ 1.76298747e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -8.22713004e-01]\n",
            " [ 5.31859245e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -2.92115678e-01]\n",
            " [ 8.87419743e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -3.24989212e-01]\n",
            " [-5.94082332e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   3.11225895e-01]\n",
            " [ 5.31859245e-01 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -5.08368084e-01]\n",
            " [ 3.54078996e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -7.33548493e-02]\n",
            " [ 1.77632099e+00  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -5.81772441e-01]\n",
            " [-7.71862581e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -5.90749953e-01]\n",
            " [ 4.13339079e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   8.78921466e-01]\n",
            " [-6.07415851e-02  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -1.28012051e-01]\n",
            " [ 7.09639494e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -6.30884709e-01]\n",
            " [ 2.94818913e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -9.19485295e-01]\n",
            " [-9.49642830e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -1.12847648e+00]\n",
            " [ 1.48002057e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -8.29182093e-01]\n",
            " [ 8.87419743e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -3.18256078e-01]\n",
            " [-4.75562166e-01 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -6.79600911e-01]\n",
            " [ 7.09639494e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -9.74274519e-01]\n",
            " [ 9.46679826e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -1.55076607e-01]\n",
            " [-1.06816300e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   3.71692074e-01]\n",
            " [-4.16302083e-01 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -4.29682837e-01]\n",
            " [ 5.77785809e-02  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -8.35519160e-01]\n",
            " [-1.30520333e+00  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   1.57745106e+00]\n",
            " [-1.20001668e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   1.70643678e+00]\n",
            " [ 1.71706090e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "   3.79613408e-01]\n",
            " [ 3.54078996e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -5.34772529e-01]\n",
            " [-7.71862581e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -6.75772266e-01]\n",
            " [-1.72002391e+00 -1.10554160e+00  1.10554160e+00  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   5.00859320e-02]\n",
            " [-1.24594325e+00  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00  1.05131497e+00 -1.05131497e+00\n",
            "  -3.07034189e-01]\n",
            " [-1.79261751e-01  9.04534034e-01 -9.04534034e-01  1.20373568e+00\n",
            "  -7.20407761e-01 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -1.57056941e-01]\n",
            " [ 1.36150041e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "  -7.20407761e-01  1.73205081e+00 -9.51189731e-01  9.51189731e-01\n",
            "  -6.00206045e-02]\n",
            " [-6.07415851e-02  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "   3.99020675e-01]\n",
            " [ 1.77632099e+00 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "   6.06823659e-01]\n",
            " [ 8.87419743e-01 -1.10554160e+00  1.10554160e+00 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01 -9.51189731e-01  9.51189731e-01\n",
            "  -7.79145669e-01]\n",
            " [-2.97781917e-01  9.04534034e-01 -9.04534034e-01 -8.30747161e-01\n",
            "   1.38810276e+00 -5.77350269e-01  1.05131497e+00 -1.05131497e+00\n",
            "  -3.17860012e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying PCA\n"
      ],
      "metadata": {
        "id": "VNIwMtstIj9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
        "X_train = kpca.fit_transform(X_train)\n",
        "X_test = kpca.transform(X_test)"
      ],
      "metadata": {
        "id": "zOO5f3lGIqYR"
      },
      "execution_count": 771,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmzFJ6T-B11r"
      },
      "source": [
        "## Training the SVM model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1264d66-f772-428f-8166-176ee9ba85aa",
        "id": "q0Aaxu51B11s"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 772,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-34 {color: black;background-color: white;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" checked><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 772
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du1WwxGmB11s"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "2d3b5039-c244-46a6-df06-9d9396c6512b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ020RDSB11s"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 773,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 2]\n",
            " [0 4]\n",
            " [0 3]\n",
            " [0 3]\n",
            " [0 3]\n",
            " [0 1]\n",
            " [0 2]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 1]\n",
            " [0 4]\n",
            " [0 2]\n",
            " [0 4]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 3]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 2]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 3]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 2]\n",
            " [0 1]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 3]\n",
            " [0 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoxToZrCB11s"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "015f43b9-9b61-4e2c-c90c-cb4bfb8de1a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA3OPz-6B11s"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 774,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[35  0  0  0  0]\n",
            " [12  0  0  0  0]\n",
            " [ 5  0  0  0  0]\n",
            " [ 6  0  0  0  0]\n",
            " [22  0  0  0  0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4375"
            ]
          },
          "metadata": {},
          "execution_count": 774
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE6CqvtdJHwv"
      },
      "source": [
        "# Trying Different number of PCA components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW7R4eYnJHw4"
      },
      "source": [
        "## Importing the dataset and encoding categorical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpoD10ddJHw4"
      },
      "source": [
        "dataset = pd.read_csv('drug200.csv')\n",
        "\n",
        "# Applying the binary encoder for SEX\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Sex'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "# Applying the OneHot encoder for blood pressure\n",
        "OneHot = ce.OneHotEncoder(cols=['BP'])\n",
        "dataset = OneHot.fit_transform(dataset)\n",
        "\n",
        "#Applaying binary encoder for Cholesterol\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Cholesterol'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "#spliting variables into depended and target value\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Applying label encoding to the target variable 'Drug'\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 775,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlzXUnA3JHw5"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNMzIBbTJHw5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
      ],
      "execution_count": 776,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "1c8d08fc-730c-485f-e566-a9dc908c168b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xieNsgFmJHw5"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 777,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[31.     1.     0.    ...  1.     0.    11.227]\n",
            " [43.     1.     0.    ...  0.     1.    13.972]\n",
            " [16.     0.     1.    ...  1.     0.    15.516]\n",
            " ...\n",
            " [15.     1.     0.    ...  0.     1.     9.084]\n",
            " [49.     0.     1.    ...  1.     0.     9.381]\n",
            " [38.     1.     0.    ...  0.     1.    18.295]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "afc8fb44-290a-4e23-c552-45fef0573516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIUVRUm0JHw5"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 778,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 0 0 2 3 4 1 4 0 0 0 0 0 4 0 0 4 2 2 0 4 1 0 0 4 0 0 0 2 0 0 0 0 4\n",
            " 2 4 4 3 1 2 0 4 0 0 2 4 0 1 0 0 4 4 4 0 1 0 4 2 0 1 1 1 0 2 0 3 3 1 4 1 0\n",
            " 0 4 0 4 0 4 1 0 0 0 0 4 0 4 0 3 0 3 0 4 0 0 4 1 0 4 0 4 4 3 2 0 0 4 0 0 4\n",
            " 3 3 0 4 4 4 4 4 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "793848eb-3364-4211-c0a8-a72395e52bb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TqNv4awJHw5"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 779,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[48.     0.     1.     0.     1.     0.     0.     1.    15.036]\n",
            " [34.     1.     0.     1.     0.     0.     0.     1.    18.703]\n",
            " [36.     1.     0.     0.     1.     0.     1.     0.    11.424]\n",
            " [47.     1.     0.     0.     1.     0.     0.     1.    13.093]\n",
            " [39.     1.     0.     0.     1.     0.     1.     0.    13.938]\n",
            " [22.     1.     0.     0.     0.     1.     0.     1.    11.953]\n",
            " [49.     0.     1.     0.     0.     1.     0.     1.    16.275]\n",
            " [65.     0.     1.     0.     1.     0.     1.     0.    13.769]\n",
            " [47.     0.     1.     0.     0.     1.     1.     0.     6.683]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     8.7  ]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     6.269]\n",
            " [72.     0.     1.     0.     1.     0.     1.     0.    14.642]\n",
            " [23.     1.     0.     0.     0.     1.     0.     1.    12.26 ]\n",
            " [49.     1.     0.     0.     1.     0.     1.     0.    11.014]\n",
            " [36.     0.     1.     1.     0.     0.     0.     1.    11.198]\n",
            " [39.     0.     1.     0.     0.     1.     1.     0.    17.225]\n",
            " [17.     1.     0.     0.     0.     1.     1.     0.    10.832]\n",
            " [32.     0.     1.     1.     0.     0.     1.     0.    10.292]\n",
            " [16.     1.     0.     0.     1.     0.     0.     1.    12.006]\n",
            " [51.     0.     1.     0.     1.     0.     1.     0.    23.003]\n",
            " [38.     0.     1.     1.     0.     0.     1.     0.    11.326]\n",
            " [45.     1.     0.     0.     1.     0.     1.     0.     8.37 ]\n",
            " [58.     0.     1.     0.     1.     0.     0.     1.    38.247]\n",
            " [55.     0.     1.     1.     0.     0.     0.     1.    10.977]\n",
            " [32.     0.     1.     0.     0.     1.     0.     1.     7.477]\n",
            " [41.     1.     0.     0.     1.     0.     0.     1.    11.037]\n",
            " [59.     1.     0.     1.     0.     0.     0.     1.    13.935]\n",
            " [37.     0.     1.     1.     0.     0.     1.     0.    23.091]\n",
            " [26.     0.     1.     0.     1.     0.     0.     1.    14.16 ]\n",
            " [24.     0.     1.     0.     0.     1.     0.     1.    10.605]\n",
            " [52.     1.     0.     0.     1.     0.     1.     0.    32.922]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.    12.879]\n",
            " [68.     0.     1.     0.     0.     1.     1.     0.    27.05 ]\n",
            " [32.     0.     1.     0.     1.     0.     0.     1.     9.712]\n",
            " [28.     0.     1.     0.     1.     0.     0.     1.    19.796]\n",
            " [72.     1.     0.     0.     1.     0.     0.     1.     6.769]\n",
            " [58.     1.     0.     1.     0.     0.     0.     1.    18.991]\n",
            " [24.     1.     0.     0.     0.     1.     0.     1.    25.786]\n",
            " [33.     0.     1.     0.     1.     0.     0.     1.    33.486]\n",
            " [74.     1.     0.     1.     0.     0.     0.     1.     9.567]\n",
            " [41.     1.     0.     1.     0.     0.     1.     0.    15.156]\n",
            " [48.     1.     0.     1.     0.     0.     1.     0.    10.446]\n",
            " [18.     0.     1.     0.     0.     1.     1.     0.     8.75 ]\n",
            " [38.     0.     1.     0.     1.     0.     1.     0.    29.875]\n",
            " [41.     0.     1.     0.     0.     1.     1.     0.    22.905]\n",
            " [73.     0.     1.     1.     0.     0.     0.     1.    18.348]\n",
            " [74.     0.     1.     0.     1.     0.     0.     1.    20.942]\n",
            " [34.     1.     0.     0.     0.     1.     0.     1.    22.456]\n",
            " [68.     1.     0.     1.     0.     0.     0.     1.    11.009]\n",
            " [40.     0.     1.     0.     1.     0.     1.     0.    11.349]\n",
            " [37.     0.     1.     1.     0.     0.     0.     1.    13.091]\n",
            " [60.     1.     0.     1.     0.     0.     1.     0.     8.621]\n",
            " [70.     0.     1.     0.     0.     1.     0.     1.    20.489]\n",
            " [23.     0.     1.     1.     0.     0.     0.     1.    25.355]\n",
            " [25.     1.     0.     0.     0.     1.     0.     1.    19.011]\n",
            " [50.     1.     0.     1.     0.     0.     0.     1.     7.49 ]\n",
            " [50.     1.     0.     0.     0.     1.     1.     0.    15.79 ]\n",
            " [42.     1.     0.     1.     0.     0.     1.     0.    12.766]\n",
            " [34.     0.     1.     0.     1.     0.     1.     0.    12.923]\n",
            " [45.     1.     0.     0.     1.     0.     1.     0.    10.017]\n",
            " [69.     1.     0.     0.     1.     0.     1.     0.    11.455]\n",
            " [18.     0.     1.     1.     0.     0.     0.     1.    37.188]\n",
            " [34.     0.     1.     1.     0.     0.     1.     0.    19.199]\n",
            " [58.     0.     1.     0.     1.     0.     0.     1.    26.645]\n",
            " [67.     0.     1.     0.     0.     1.     0.     1.    15.891]\n",
            " [69.     1.     0.     0.     1.     0.     0.     1.    15.478]\n",
            " [55.     1.     0.     0.     0.     1.     1.     0.     7.261]\n",
            " [43.     1.     0.     0.     1.     0.     1.     0.    19.368]\n",
            " [22.     1.     0.     1.     0.     0.     1.     0.    28.294]\n",
            " [65.     0.     1.     1.     0.     0.     1.     0.    31.876]\n",
            " [22.     0.     1.     1.     0.     0.     1.     0.    22.818]\n",
            " [56.     1.     0.     0.     1.     0.     0.     1.    15.015]\n",
            " [57.     0.     1.     0.     0.     1.     0.     1.    14.216]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    17.069]\n",
            " [42.     1.     0.     0.     1.     0.     0.     1.    20.013]\n",
            " [22.     1.     0.     0.     1.     0.     0.     1.     8.151]\n",
            " [52.     1.     0.     0.     0.     1.     0.     1.     9.894]\n",
            " [64.     1.     0.     1.     0.     0.     1.     0.    20.932]\n",
            " [36.     0.     1.     0.     0.     1.     0.     1.    16.753]\n",
            " [65.     1.     0.     1.     0.     0.     1.     0.    11.34 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "c7c30841-0518-4127-beb1-36a2d5e5b4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlybEifUJHw5"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 780,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 4 3 4 4 0 4 4 1 1 4 4 4 1 0 4 1 3 0 1 4 0 2 4 3 2 0 3 4 0 4 0 3 0 3 0\n",
            " 0 0 2 0 1 4 0 0 0 0 0 2 4 1 2 0 0 0 1 0 1 4 4 4 0 0 0 0 0 4 0 0 0 0 0 4 0\n",
            " 0 3 4 0 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiBX5XwYJHw6"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGclVXqzJHw6"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 781,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "c731ccfe-c556-435c-f660-d2b7871c5edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hELk4c6KJHw6"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 782,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.78670942  0.95118973 -0.95118973 ...  1.0168079  -1.0168079\n",
            "  -0.67976656]\n",
            " [-0.07016194  0.95118973 -0.95118973 ... -0.98346994  0.98346994\n",
            "  -0.29338227]\n",
            " [-1.68239378 -1.05131497  1.05131497 ...  1.0168079  -1.0168079\n",
            "  -0.07604991]\n",
            " ...\n",
            " [-1.74210607  0.95118973 -0.95118973 ... -0.98346994  0.98346994\n",
            "  -0.98141375]\n",
            " [ 0.2881118  -1.05131497  1.05131497 ...  1.0168079  -1.0168079\n",
            "  -0.93960823]\n",
            " [-0.36872339  0.95118973 -0.95118973 ... -0.98346994  0.98346994\n",
            "   0.3151202 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "99ac471d-ebbb-4769-9ddc-19dc90fb724b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNQA_q8UJHw6"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 783,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.22839951 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.14361437]\n",
            " [-0.60757255  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994  0.37254999]\n",
            " [-0.48814797  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.65203698]\n",
            " [ 0.16868722  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.4171097 ]\n",
            " [-0.3090111   0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.29816809]\n",
            " [-1.32412004  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.5775753 ]\n",
            " [ 0.2881118  -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994  0.03078641]\n",
            " [ 1.24350844 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.32195641]\n",
            " [ 0.16868722 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079  -1.31937683]\n",
            " [ 0.2881118   0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -1.03546532]\n",
            " [ 0.2881118   0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -1.37765118]\n",
            " [ 1.66149448 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.19907354]\n",
            " [-1.26440775  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.5343622 ]\n",
            " [ 0.2881118   0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.70974829]\n",
            " [-0.48814797 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.68384858]\n",
            " [-0.3090111  -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079   0.16450774]\n",
            " [-1.62268149  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079  -0.73536648]\n",
            " [-0.72699713 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.81137651]\n",
            " [-1.68239378  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.57011506]\n",
            " [ 0.40753638 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079   0.977815  ]\n",
            " [-0.36872339 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.66583139]\n",
            " [ 0.04926264  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -1.08191589]\n",
            " [ 0.82552241 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994  3.12354982]\n",
            " [ 0.64638554 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.71495638]\n",
            " [-0.72699713 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -1.20761395]\n",
            " [-0.18958652  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.70651083]\n",
            " [ 0.8852347   0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.29859036]\n",
            " [-0.42843568 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   0.99020182]\n",
            " [-1.08527087 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.26691952]\n",
            " [-1.20469546 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.76731884]\n",
            " [ 0.46724867  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079   2.37400653]\n",
            " [-0.96584629 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.44723219]\n",
            " [ 1.42264531 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079   1.5474679 ]\n",
            " [-0.72699713 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.8930169 ]\n",
            " [-0.96584629 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994  0.52639991]\n",
            " [ 1.66149448  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -1.30727153]\n",
            " [ 0.82552241  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994  0.41308867]\n",
            " [-1.20469546  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994  1.36954814]\n",
            " [-0.66728484 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994  2.45339478]\n",
            " [ 1.78091906  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.913427  ]\n",
            " [-0.18958652  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.12672325]\n",
            " [ 0.22839951  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.78969957]\n",
            " [-1.5629692  -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079  -1.02842735]\n",
            " [-0.36872339 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079   1.94511293]\n",
            " [-0.18958652 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079   0.96402059]\n",
            " [ 1.72120677 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994  0.32258044]\n",
            " [ 1.78091906 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994  0.68771007]\n",
            " [-0.60757255  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994  0.90081966]\n",
            " [ 1.42264531  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.71045209]\n",
            " [-0.24929881 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.66259392]\n",
            " [-0.42843568 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.41739122]\n",
            " [ 0.94494699  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -1.0465853 ]\n",
            " [ 1.5420699  -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994  0.62394611]\n",
            " [-1.26440775 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994  1.30888088]\n",
            " [-1.14498317  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994  0.41590386]\n",
            " [ 0.34782409  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994 -1.20578408]\n",
            " [ 0.34782409  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079  -0.03748186]\n",
            " [-0.12987423  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.46313799]\n",
            " [-0.60757255 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.44103878]\n",
            " [ 0.04926264  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.85008532]\n",
            " [ 1.48235761  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.64767344]\n",
            " [-1.5629692  -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "  -0.98346994  0.98346994  2.97448572]\n",
            " [-0.60757255 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   0.44236661]\n",
            " [ 0.82552241 -1.05131497  1.05131497 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994  1.49046038]\n",
            " [ 1.36293302 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.02326517]\n",
            " [ 1.48235761  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.08139876]\n",
            " [ 0.64638554  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "   1.0168079  -1.0168079  -1.23801796]\n",
            " [-0.07016194  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "   1.0168079  -1.0168079   0.46615493]\n",
            " [-1.32412004  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   1.72257247]\n",
            " [ 1.24350844 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   2.2267723 ]\n",
            " [-1.32412004 -1.05131497  1.05131497  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   0.95177453]\n",
            " [ 0.70609783  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -0.14657032]\n",
            " [ 0.76581012 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.259037  ]\n",
            " [-0.78670942  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   0.14254929]\n",
            " [-0.12987423  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994  0.55694468]\n",
            " [-1.32412004  0.95118973 -0.95118973 -0.83074716  1.59041245 -0.66766993\n",
            "  -0.98346994  0.98346994 -1.11274218]\n",
            " [ 0.46724867  0.95118973 -0.95118973 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994 -0.86739871]\n",
            " [ 1.18379615  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079   0.68630248]\n",
            " [-0.48814797 -1.05131497  1.05131497 -0.83074716 -0.62876771  1.49774605\n",
            "  -0.98346994  0.98346994  0.09806935]\n",
            " [ 1.24350844  0.95118973 -0.95118973  1.20373568 -0.62876771 -0.66766993\n",
            "   1.0168079  -1.0168079  -0.66386076]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying PCA\n"
      ],
      "metadata": {
        "id": "gjinAAJ3JHw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "kpca = KernelPCA(n_components = 6, kernel = 'rbf')\n",
        "X_train = kpca.fit_transform(X_train)\n",
        "X_test = kpca.transform(X_test)"
      ],
      "metadata": {
        "id": "DA0BVnV7JHw6"
      },
      "execution_count": 784,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKu7NnrHJHw6"
      },
      "source": [
        "## Training the SVM model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "49c2ea9a-9398-4762-fa07-d4741a9dcfdc",
        "id": "DKzZqrhlJHw6"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 785,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-35 {color: black;background-color: white;}#sk-container-id-35 pre{padding: 0;}#sk-container-id-35 div.sk-toggleable {background-color: white;}#sk-container-id-35 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-35 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-35 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-35 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-35 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-35 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-35 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-35 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-35 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-35 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-35 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-35 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-35 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-35 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-35 div.sk-item {position: relative;z-index: 1;}#sk-container-id-35 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-35 div.sk-item::before, #sk-container-id-35 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-35 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-35 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-35 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-35 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-35 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-35 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-35 div.sk-label-container {text-align: center;}#sk-container-id-35 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-35 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-35\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" checked><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 785
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iWgbLc2JHw7"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "20430d57-a5c9-4eeb-90bc-1f9d12eb8532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLLZkaNoJHw7"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 786,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 0]\n",
            " [1 0]\n",
            " [0 4]\n",
            " [0 3]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [4 0]\n",
            " [0 4]\n",
            " [4 4]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 1]\n",
            " [4 0]\n",
            " [4 4]\n",
            " [0 1]\n",
            " [0 3]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 2]\n",
            " [4 4]\n",
            " [0 3]\n",
            " [1 2]\n",
            " [0 0]\n",
            " [3 3]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [4 0]\n",
            " [3 3]\n",
            " [0 0]\n",
            " [0 3]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 2]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [4 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 2]\n",
            " [4 4]\n",
            " [0 1]\n",
            " [1 2]\n",
            " [4 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [4 0]\n",
            " [1 1]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [4 0]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [4 4]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 3]\n",
            " [0 4]\n",
            " [0 0]\n",
            " [4 0]\n",
            " [1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO3VPDGPJHw7"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "d7550ba5-7c1b-4394-ab36-d42644b3eff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdO9NROxJHw7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 787,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[24  4  0  1  8]\n",
            " [ 4  5  0  0  0]\n",
            " [ 1  5  0  0  0]\n",
            " [ 5  0  0  2  0]\n",
            " [12  0  0  0  9]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 787
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhaok9QQKbeX"
      },
      "source": [
        "# Applying the other Models (KNN, NCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htAePuoBKbef"
      },
      "source": [
        "## Importing the dataset and encoding categorical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YdFoU2xKbef"
      },
      "source": [
        "dataset = pd.read_csv('drug200.csv')\n",
        "\n",
        "# Applying the binary encoder for SEX\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Sex'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "# Applying the OneHot encoder for blood pressure\n",
        "OneHot = ce.OneHotEncoder(cols=['BP'])\n",
        "dataset = OneHot.fit_transform(dataset)\n",
        "\n",
        "#Applaying binary encoder for Cholesterol\n",
        "binary_encoder = ce.BinaryEncoder(cols=['Cholesterol'])\n",
        "dataset = binary_encoder.fit_transform(dataset)\n",
        "\n",
        "#spliting variables into depended and target value\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "# Applying label encoding to the target variable 'Drug'\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 788,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNc8WTINKbef"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDaDm_voKbef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)"
      ],
      "execution_count": 789,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "643865b1-bf7a-4c28-d91c-91469548108a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsh83Q0AKbef"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 790,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[23.     0.     1.    ...  0.     1.    25.355]\n",
            " [23.     1.     0.    ...  0.     1.     8.011]\n",
            " [67.     1.     0.    ...  1.     0.    20.693]\n",
            " ...\n",
            " [37.     0.     1.    ...  1.     0.    12.006]\n",
            " [43.     1.     0.    ...  1.     0.    19.368]\n",
            " [31.     1.     0.    ...  0.     1.    30.366]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "23ceb080-d3b3-4461-c323-d7642738d44b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Hge5ZZKbef"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 791,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 4 0 0 0 0 3 0 0 2 0 4 4 0 1 2 4 1 0 4 0 0 4 2 4 1 4 3 3 3 1 3 4 0 4\n",
            " 0 4 0 2 4 3 4 4 0 1 0 1 4 4 0 4 0 0 0 0 0 2 0 4 0 2 0 0 0 4 0 0 0 0 1 4 3\n",
            " 4 0 2 1 2 0 0 0 4 1 0 0 3 4 0 4 0 0 4 4 0 4 1 0 0 0 4 0 1 0 4 0 0 0 4 4 4\n",
            " 4 2 4 0 4 0 4 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "254071de-09c6-499c-b251-257f35cac487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxy47SSBKbef"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 792,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[58.     1.     0.     1.     0.     0.     0.     1.    18.991]\n",
            " [50.     0.     1.     0.     0.     1.     0.     1.    12.703]\n",
            " [72.     0.     1.     0.     1.     0.     1.     0.    14.642]\n",
            " [24.     0.     1.     0.     0.     1.     0.     1.    10.605]\n",
            " [47.     1.     0.     1.     0.     0.     0.     1.    10.403]\n",
            " [33.     0.     1.     0.     1.     0.     0.     1.    33.486]\n",
            " [26.     0.     1.     1.     0.     0.     1.     0.    12.307]\n",
            " [53.     1.     0.     0.     0.     1.     0.     1.    14.133]\n",
            " [39.     1.     0.     0.     1.     0.     1.     0.    13.938]\n",
            " [56.     0.     1.     1.     0.     0.     0.     1.    25.395]\n",
            " [28.     0.     1.     1.     0.     0.     1.     0.    18.809]\n",
            " [32.     0.     1.     1.     0.     0.     1.     0.    10.292]\n",
            " [74.     0.     1.     0.     1.     0.     0.     1.    20.942]\n",
            " [64.     0.     1.     0.     1.     0.     1.     0.    25.741]\n",
            " [59.     0.     1.     0.     1.     0.     0.     1.    10.444]\n",
            " [61.     0.     1.     0.     1.     0.     0.     1.    18.043]\n",
            " [36.     1.     0.     0.     1.     0.     1.     0.    11.424]\n",
            " [22.     1.     0.     0.     1.     0.     0.     1.     8.151]\n",
            " [56.     1.     0.     0.     0.     1.     0.     1.     8.966]\n",
            " [32.     0.     1.     1.     0.     0.     1.     0.    25.974]\n",
            " [60.     1.     0.     0.     0.     1.     0.     1.    15.171]\n",
            " [56.     1.     0.     0.     1.     0.     0.     1.    15.015]\n",
            " [67.     1.     0.     0.     0.     1.     1.     0.     9.514]\n",
            " [28.     1.     0.     0.     0.     1.     0.     1.    27.064]\n",
            " [40.     0.     1.     0.     1.     0.     1.     0.    11.349]\n",
            " [47.     1.     0.     0.     1.     0.     0.     1.    10.114]\n",
            " [24.     1.     0.     0.     0.     1.     0.     1.    25.786]\n",
            " [72.     1.     0.     0.     1.     0.     0.     1.     6.769]\n",
            " [58.     0.     1.     0.     1.     0.     0.     1.    38.247]\n",
            " [19.     0.     1.     1.     0.     0.     0.     1.    13.313]\n",
            " [54.     1.     0.     0.     0.     1.     0.     1.    24.658]\n",
            " [49.     1.     0.     1.     0.     0.     1.     0.     6.269]\n",
            " [28.     0.     1.     0.     1.     0.     0.     1.    19.796]\n",
            " [68.     0.     1.     1.     0.     0.     1.     0.    10.189]\n",
            " [64.     1.     0.     1.     0.     0.     1.     0.    20.932]\n",
            " [20.     1.     0.     1.     0.     0.     1.     0.    35.639]\n",
            " [43.     1.     0.     0.     1.     0.     0.     1.    15.376]\n",
            " [47.     0.     1.     0.     1.     0.     0.     1.    11.767]\n",
            " [51.     0.     1.     0.     0.     1.     0.     1.    13.597]\n",
            " [63.     1.     0.     0.     0.     1.     0.     1.    25.917]\n",
            " [67.     0.     1.     0.     0.     1.     0.     1.    15.891]\n",
            " [38.     0.     1.     0.     1.     0.     1.     0.    29.875]\n",
            " [51.     1.     0.     1.     0.     0.     1.     0.    11.343]\n",
            " [41.     0.     1.     0.     0.     1.     1.     0.    22.905]\n",
            " [55.     1.     0.     0.     0.     1.     1.     0.     7.261]\n",
            " [65.     1.     0.     1.     0.     0.     1.     0.    11.34 ]\n",
            " [42.     0.     1.     0.     1.     0.     1.     0.    29.271]\n",
            " [64.     1.     0.     0.     0.     1.     0.     1.     7.761]\n",
            " [46.     0.     1.     1.     0.     0.     0.     1.    34.686]\n",
            " [36.     0.     1.     1.     0.     0.     0.     1.    11.198]\n",
            " [28.     0.     1.     0.     0.     1.     0.     1.    19.675]\n",
            " [39.     0.     1.     0.     0.     1.     1.     0.     9.709]\n",
            " [28.     0.     1.     0.     1.     0.     0.     1.    13.127]\n",
            " [49.     1.     0.     0.     1.     0.     1.     0.    11.014]\n",
            " [32.     0.     1.     0.     1.     0.     0.     1.     9.712]\n",
            " [70.     1.     0.     1.     0.     0.     0.     1.     9.849]\n",
            " [34.     1.     0.     1.     0.     0.     0.     1.    18.703]\n",
            " [24.     1.     0.     1.     0.     0.     1.     0.     9.475]\n",
            " [55.     0.     1.     1.     0.     0.     0.     1.    10.977]\n",
            " [45.     1.     0.     0.     1.     0.     0.     1.    17.951]\n",
            " [72.     1.     0.     0.     1.     0.     0.     1.    16.31 ]\n",
            " [36.     0.     1.     0.     0.     1.     0.     1.    16.753]\n",
            " [68.     1.     0.     1.     0.     0.     0.     1.    11.009]\n",
            " [34.     0.     1.     0.     1.     0.     1.     0.    12.923]\n",
            " [57.     0.     1.     1.     0.     0.     1.     0.     9.945]\n",
            " [15.     1.     0.     1.     0.     0.     1.     0.    17.206]\n",
            " [23.     1.     0.     0.     1.     0.     0.     1.     7.298]\n",
            " [41.     0.     1.     0.     1.     0.     1.     0.    18.739]\n",
            " [59.     0.     1.     0.     0.     1.     0.     1.    13.884]\n",
            " [16.     0.     1.     1.     0.     0.     1.     0.    15.516]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    11.871]\n",
            " [69.     0.     1.     0.     0.     1.     0.     1.    10.065]\n",
            " [19.     0.     1.     1.     0.     0.     1.     0.    25.969]\n",
            " [25.     1.     0.     0.     0.     1.     0.     1.    19.011]\n",
            " [39.     1.     0.     1.     0.     0.     0.     1.     9.664]\n",
            " [32.     0.     1.     0.     1.     0.     1.     0.    10.84 ]\n",
            " [31.     1.     0.     1.     0.     0.     1.     0.    11.227]\n",
            " [37.     0.     1.     1.     0.     0.     0.     1.    13.091]\n",
            " [34.     1.     0.     0.     0.     1.     0.     1.    22.456]\n",
            " [26.     0.     1.     1.     0.     0.     1.     0.    19.161]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "5164d446-2857-4e7b-f8d6-caea40d02a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ9FhSeiKbeg"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 793,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 4 4 4 1 0 1 4 4 0 0 1 0 0 3 0 4 3 4 0 0 0 4 0 4 3 0 3 0 1 0 1 0 2 0 0 0\n",
            " 3 4 0 0 0 2 0 4 2 0 4 0 1 0 4 3 4 3 2 0 1 2 0 0 0 2 4 2 0 3 0 4 0 1 4 0 0\n",
            " 1 4 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3TIaYEVKbeg"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dBR4prUKbeg"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 794,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "a2c7a3e8-30ac-456c-ad4b-43101ace96d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8fh3s1yKbeg"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 795,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.27185288 -1.1055416   1.1055416  ... -1.06904497  1.06904497\n",
            "   1.29833232]\n",
            " [-1.27185288  0.90453403 -0.90453403 ... -1.06904497  1.06904497\n",
            "  -1.131184  ]\n",
            " [ 1.36163073  0.90453403 -0.90453403 ...  0.93541435 -0.93541435\n",
            "   0.64528774]\n",
            " ...\n",
            " [-0.43392628 -1.1055416   1.1055416  ...  0.93541435 -0.93541435\n",
            "  -0.57157159]\n",
            " [-0.07481488  0.90453403 -0.90453403 ...  0.93541435 -0.93541435\n",
            "   0.45968413]\n",
            " [-0.79303768  0.90453403 -0.90453403 ... -1.06904497  1.06904497\n",
            "   2.00026418]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "be64be52-a5e3-4ca8-9a81-4d062f0d48c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zIu9_xzKbeg"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 796,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.82296363  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497  0.40687464]\n",
            " [ 0.34414843 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.47393708]\n",
            " [ 1.66089023 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.20232545]\n",
            " [-1.21200098 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.76782115]\n",
            " [ 0.16459273  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.79611695]\n",
            " [-0.67333388 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  2.43730817]\n",
            " [-1.09229718 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.52940805]\n",
            " [ 0.52370413  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.27362526]\n",
            " [-0.31422248  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.30094051]\n",
            " [ 0.70325983 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497  1.30393544]\n",
            " [-0.97259338 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  0.38138041]\n",
            " [-0.73318578 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.81166563]\n",
            " [ 1.78059403 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  0.68016722]\n",
            " [ 1.18207503 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435  1.3524025 ]\n",
            " [ 0.88281553 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.79037374]\n",
            " [ 1.00251933 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  0.27408051]\n",
            " [-0.49377818  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.6530971 ]\n",
            " [-1.33170478  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -1.11157305]\n",
            " [ 0.70325983  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.99740932]\n",
            " [-0.73318578 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  1.38504072]\n",
            " [ 0.94266743  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.12822408]\n",
            " [ 0.70325983  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.15007628]\n",
            " [ 1.36163073  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "   0.93541435 -0.93541435 -0.92064647]\n",
            " [-0.97259338  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  1.53772596]\n",
            " [-0.25437058 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.66360297]\n",
            " [ 0.16459273  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.83659955]\n",
            " [-1.21200098  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  1.35870602]\n",
            " [ 1.66089023  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -1.30516113]\n",
            " [ 0.82296363 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  3.10422048]\n",
            " [-1.51126048 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.38848938]\n",
            " [ 0.58355603  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  1.20069781]\n",
            " [ 0.28429653  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -1.37520023]\n",
            " [-0.97259338 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  0.5196376 ]\n",
            " [ 1.42148263 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.82609368]\n",
            " [ 1.18207503  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  0.67876643]\n",
            " [-1.45140858  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  2.73889654]\n",
            " [-0.07481488  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.09950805]\n",
            " [ 0.16459273 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.60505028]\n",
            " [ 0.40400033 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.34870717]\n",
            " [ 1.12222313  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  1.37705627]\n",
            " [ 1.36163073 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.02736778]\n",
            " [-0.37407438 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435  1.93148579]\n",
            " [ 0.40400033  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.66444344]\n",
            " [-0.19451868 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "   0.93541435 -0.93541435  0.95514072]\n",
            " [ 0.64340793  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "   0.93541435 -0.93541435 -1.23624265]\n",
            " [ 1.24192693  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.66486367]\n",
            " [-0.13466678 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435  1.84687855]\n",
            " [ 1.18207503  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -1.16620355]\n",
            " [ 0.10474083 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497  2.60540201]\n",
            " [-0.49377818 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.68475478]\n",
            " [-0.97259338 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  0.50268813]\n",
            " [-0.31422248 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "   0.93541435 -0.93541435 -0.89333122]\n",
            " [-0.97259338 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.41454393]\n",
            " [ 0.28429653  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.71052917]\n",
            " [-0.73318578 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.89291098]\n",
            " [ 1.54118643  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.87372027]\n",
            " [-0.61348198  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497  0.36653212]\n",
            " [-1.21200098  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.92610952]\n",
            " [ 0.64340793 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.71571206]\n",
            " [ 0.04488893  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  0.26119332]\n",
            " [ 1.66089023  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497  0.03132499]\n",
            " [-0.49377818 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  0.09337963]\n",
            " [ 1.42148263  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.71122956]\n",
            " [-0.61348198 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.44311988]\n",
            " [ 0.76311173 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.86027276]\n",
            " [-1.75066808  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  0.15683506]\n",
            " [-1.27185288  0.90453403 -0.90453403 -0.80239368  1.52752523 -0.66766993\n",
            "  -1.06904497  1.06904497 -1.23105976]\n",
            " [-0.19451868 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435  0.37157494]\n",
            " [ 0.88281553 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.30850473]\n",
            " [-1.69081618 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.0798971 ]\n",
            " [-0.79303768  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.59048215]\n",
            " [ 1.48133453 -1.1055416   1.1055416  -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497 -0.84346338]\n",
            " [-1.51126048 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  1.38434033]\n",
            " [-1.15214908  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  0.40967621]\n",
            " [-0.31422248  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.89963474]\n",
            " [-0.73318578 -1.1055416   1.1055416  -0.80239368  1.52752523 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.73490277]\n",
            " [-0.79303768  0.90453403 -0.90453403  1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435 -0.68069251]\n",
            " [-0.43392628 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "  -1.06904497  1.06904497 -0.41958674]\n",
            " [-0.61348198  0.90453403 -0.90453403 -0.80239368 -0.65465367  1.49774605\n",
            "  -1.06904497  1.06904497  0.89224561]\n",
            " [-1.09229718 -1.1055416   1.1055416   1.24627103 -0.65465367 -0.66766993\n",
            "   0.93541435 -0.93541435  0.43068794]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENG_D6QAKbeh"
      },
      "source": [
        "## Training the KNN model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e4eff425-0f50-47d9-901d-291f137daa73",
        "id": "kfNV4JoZKbeh"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifierKNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifierKNN.fit(X_train, y_train)"
      ],
      "execution_count": 797,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-36 {color: black;background-color: white;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" checked><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 797
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the Nearest Class Centroid model"
      ],
      "metadata": {
        "id": "Izq2i_wLK3yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestCentroid\n",
        "classifierNC = NearestCentroid(metric='euclidean')\n",
        "classifierNC.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qqOJhMxCK8rQ",
        "outputId": "a3a5d7a4-013b-4457-a684-99c9604f040b"
      },
      "execution_count": 798,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestCentroid()"
            ],
            "text/html": [
              "<style>#sk-container-id-37 {color: black;background-color: white;}#sk-container-id-37 pre{padding: 0;}#sk-container-id-37 div.sk-toggleable {background-color: white;}#sk-container-id-37 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-37 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-37 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-37 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-37 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-37 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-37 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-37 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-37 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-37 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-37 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-37 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-37 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-37 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-37 div.sk-item {position: relative;z-index: 1;}#sk-container-id-37 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-37 div.sk-item::before, #sk-container-id-37 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-37 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-37 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-37 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-37 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-37 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-37 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-37 div.sk-label-container {text-align: center;}#sk-container-id-37 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-37 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-37\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestCentroid()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" checked><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestCentroid</label><div class=\"sk-toggleable__content\"><pre>NearestCentroid()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 798
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juCz4GoHKbeh"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdv1Q92vKbeh"
      },
      "source": [
        "y_pred_KNN = classifierKNN.predict(X_test)\n",
        "y_pred_NC = classifierNC.predict(X_test)"
      ],
      "execution_count": 799,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7pmoLEvKbeh"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "693ca6e2-bdf1-417d-891a-1e1f34c061a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O9TtEDGKbeh"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"The accurasy score of KNN Model is: \", accuracy_score(y_test, y_pred_KNN) )\n",
        "print(\"The accurasy score of NCC Model is: \", accuracy_score(y_test, y_pred_NC) )"
      ],
      "execution_count": 800,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accurasy score of KNN Model is:  0.7\n",
            "The accurasy score of KNN Model is:  0.7625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Documendation\n"
      ],
      "metadata": {
        "id": "hNiFZzvSM8GT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "- **The Dataset:** https://www.kaggle.com/datasets/prathamtripathi/drug-classification/data\n",
        "- **Objectives of the analysis:** I tryied several methodes to find the best \"doctor\" model, so it can predict based on the features what type of drug a patient needs.\n",
        "\n",
        "# Methodology\n",
        "\n",
        "### Preprocessing Steps\n",
        "\n",
        "1. **Encoding Categorical Values**:\n",
        "   - **Binary Encoding**: Applied to the 'Sex' and 'Cholesterol' columns.\n",
        "   - **One-Hot Encoding**: Used for the 'BP' (Blood Pressure) column.\n",
        "\n",
        "2. **Feature Scaling**:\n",
        "   - **StandardScaler**: Standardizes features by removing the mean and scaling to unit variance.\n",
        "\n",
        "### Parameter Selection and Model Tuning Methods\n",
        "\n",
        "1. **Support Vector Machine (SVM)**:\n",
        "   - **Kernel**: Linear\n",
        "   - **Random State**: 0\n",
        "\n",
        "2. **K-Nearest Neighbors (KNN)**:\n",
        "   - **Number of Neighbors (n_neighbors)**: 5\n",
        "   - **Distance Metric**: Minkowski with \\( p = 2 \\) (Euclidean distance)\n",
        "\n",
        "3. **Nearest Class Centroid (NCC)**:\n",
        "   - **Metric**: Euclidean distance\n",
        "\n",
        "### Cross-Validation Strategy\n",
        "\n",
        "- **K-Fold Cross-Validation**: Different values of `n_splits` (2, 10, 15, 25) are experimented with.\n",
        "- **Shuffle**: Ensuring data is shuffled before splitting into batches.\n",
        "\n",
        "### Additional Points\n",
        "\n",
        "- **Principal Component Analysis (PCA)**: Used to reduce dimensionality.\n",
        "- **Model Comparison**: Comparing SVM with KNN and NCC models.\n",
        "\n",
        "\n",
        "# Algorithm Explanation\n",
        "\n",
        "### Support Vector Machine (SVM)\n",
        "\n",
        "- **Fundamentals**: SVM is a supervised learning algorithm used for classification and regression. It works by finding the hyperplane that best separates the classes in the feature space.\n",
        "- **Maximizing Margin**: The algorithm focuses on maximizing the margin between the data points of different classes, aiming to increase the model's generalization ability.\n",
        "- **Support Vectors**: Data points closest to the hyperplane, called support vectors, are critical in defining the hyperplane and the margin.\n",
        "\n",
        "### Nearest Neighbor (KNN)\n",
        "\n",
        "- **Basic Concept**: Classifies a data point based on how its neighbors are classified.\n",
        "- **Distance Metrics**: Often uses Euclidean distance but can use other metrics.\n",
        "- **Choosing 'K'**: The number of neighbors (K) is a crucial parameter, with a larger K smoothing the decision boundaries.\n",
        "\n",
        "### Nearest Class Centroid (NCC)\n",
        "\n",
        "- **Principle**: Assigns a class based on the closest class centroid.\n",
        "- **Centroid Calculation**: The centroid of a class is the average of all points in that class.\n",
        "- **Suitability**: Effective when classes are compact and well-separated.\n",
        "\n",
        "\n",
        "# Results\n",
        "\n",
        "- **Simple Support Vector Machine (SVM)**: accuracy is `0.9375`\n",
        "- **Simple Support Vector Machine (SVM) with cross validation:** accuracy varies from `0.9901098` to `0.985` based on the number of splits\n",
        "- **Simple Support Vector Machine (SVM) with PCA Applayied:** accuracy varies based on the number of PCA  components with the highest `0.5`\n",
        "- **Comparative analysis with Nearest Neighbor and Nearest Class Centroid classifiers:** For NC accuracy is `0.7625` and for KNN `0.7`\n",
        "\n",
        "Since I didn't initialize a random state, results might slightly vary from time to time.\n",
        "\n",
        "# Discussion\n",
        "\n",
        "The results indicate a strong performance of the Simple Support Vector Machine (SVM) model, achieving an accuracy of `0.9375`. This high accuracy underscores SVM's effectiveness in handling the dataset's linear separability. Notably, the application of cross-validation to SVM further enhanced its robustness, with accuracy reaching as high as `0.9901098`, depending on the number of splits. This variability in accuracy with different splits highlights the importance of cross-validation in evaluating model performance more comprehensively. However, the introduction of PCA (Principal Component Analysis) to SVM led to a significant decrease in accuracy, with the highest being only `0.5`. This suggests that dimensionality reduction via PCA might be removing critical information necessary for accurate classification in this specific dataset. In comparison, Nearest Neighbor (KNN) and Nearest Class Centroid (NCC) classifiers demonstrated lower accuracy, with NCC achieving 0.7625 and KNN 0.7. This disparity in performance could be attributed to SVM's superior ability to manage the feature space and its boundaries, as opposed to the distance-based classification approach used by KNN and the centroid-based approach of NCC.\n",
        "\n"
      ],
      "metadata": {
        "id": "TAZkFAHCNAL2"
      }
    }
  ]
}